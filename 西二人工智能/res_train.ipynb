{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (start): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (a1_1): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b1_1): Sequential()\n",
      "  (a1_2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b1_2): Sequential()\n",
      "  (a1_3): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b1_3): Sequential()\n",
      "  (a2_1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b2_1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (a2_2): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b2_2): Sequential()\n",
      "  (a2_3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b2_3): Sequential()\n",
      "  (a2_4): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b2_4): Sequential()\n",
      "  (a3_1): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_1): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (a3_2): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_2): Sequential()\n",
      "  (a3_3): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_3): Sequential()\n",
      "  (a3_4): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_4): Sequential()\n",
      "  (a3_5): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_5): Sequential()\n",
      "  (a3_6): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_6): Sequential()\n",
      "  (a4_1): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b4_1): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (a4_2): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b4_2): Sequential()\n",
      "  (a4_3): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b4_3): Sequential()\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (avg): AdaptiveAvgPool2d(output_size=1)\n",
      "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.block = {}\n",
    "        self.start = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,2,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3,2,1)\n",
    "        )\n",
    "        \n",
    "        self.a1_1,self.b1_1 = self.Residual(64,64,3,1)\n",
    "        self.a1_2,self.b1_2 = self.Residual(64,64,3,1)\n",
    "        self.a1_3,self.b1_3 = self.Residual(64,64,3,1)\n",
    "        \n",
    "        self.a2_1,self.b2_1 = self.Residual(64,128,3,2)\n",
    "        self.a2_2,self.b2_2 = self.Residual(128,128,3,1)\n",
    "        self.a2_3,self.b2_3 = self.Residual(128,128,3,1)\n",
    "        self.a2_4,self.b2_4 = self.Residual(128,128,3,1)\n",
    "        \n",
    "        self.a3_1,self.b3_1 = self.Residual(128,256,3,2)\n",
    "        self.a3_2,self.b3_2 = self.Residual(256,256,3,1)\n",
    "        self.a3_3,self.b3_3 = self.Residual(256,256,3,1)\n",
    "        self.a3_4,self.b3_4 = self.Residual(256,256,3,1)\n",
    "        self.a3_5,self.b3_5 = self.Residual(256,256,3,1)\n",
    "        self.a3_6,self.b3_6 = self.Residual(256,256,3,1)\n",
    "        \n",
    "        self.a4_1,self.b4_1 = self.Residual(256,512,3,2)\n",
    "        self.a4_2,self.b4_2 = self.Residual(512,512,3,1)\n",
    "        self.a4_3,self.b4_3 = self.Residual(512,512,3,1)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear = nn.Linear(512,2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.start(x)\n",
    "        \n",
    "        x = self.Block(self.a1_1,self.b1_1,x)\n",
    "        x = self.Block(self.a1_2,self.b1_2,x)\n",
    "        x = self.Block(self.a1_3,self.b1_3,x)\n",
    "        \n",
    "        x = self.Block(self.a2_1,self.b2_1,x)\n",
    "        x = self.Block(self.a2_2,self.b2_2,x)\n",
    "        x = self.Block(self.a2_3,self.b2_3,x)\n",
    "        x = self.Block(self.a2_4,self.b2_4,x)\n",
    "        \n",
    "        x = self.Block(self.a3_1,self.b3_1,x)\n",
    "        x = self.Block(self.a3_2,self.b3_2,x)\n",
    "        x = self.Block(self.a3_3,self.b3_3,x)\n",
    "        x = self.Block(self.a3_4,self.b3_4,x)\n",
    "        x = self.Block(self.a3_5,self.b3_5,x)\n",
    "        x = self.Block(self.a3_6,self.b3_6,x)\n",
    "        \n",
    "        x = self.Block(self.a4_1,self.b4_1,x)\n",
    "        x = self.Block(self.a4_2,self.b4_2,x)\n",
    "        x = self.Block(self.a4_3,self.b4_3,x)\n",
    "        \n",
    "        x = self.avg(x)\n",
    "        \n",
    "        x = self.linear(x.view(x.size()[0],-1))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def Residual(self,C_in,C_out,size,stride):\n",
    "            over = nn.Sequential(\n",
    "                    nn.Conv2d(C_in,C_out,size,stride,1),\n",
    "                    nn.BatchNorm2d(C_out),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(C_out,C_out,size,1,1),\n",
    "                    nn.BatchNorm2d(C_out)\n",
    "                )\n",
    "            if C_in !=C_out:   \n",
    "                change = nn.Sequential(\n",
    "                        nn.Conv2d(C_in,C_out,1,stride),\n",
    "                        nn.BatchNorm2d(C_out)\n",
    "                    )\n",
    "            else:\n",
    "                change = nn.Sequential()\n",
    "            return over,change\n",
    "        \n",
    "    def Block(self,a,b,x):\n",
    "        out = a(x)\n",
    "        x = b(x)\n",
    "        x = self.relu(x+out)\n",
    "        return x\n",
    "    \n",
    "net = Net().cuda()\n",
    "print(net)\n",
    "net.load_state_dict(torch.load('params_res_train_2_15.pkl'))\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "loss_func=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 3, 64, 64]) torch.Size([25000]) tensor([0, 0, 0,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "def load_dataset():\n",
    "    train_dataset=h5py.File('train_res_dataset.h5','r')\n",
    "    train_x=train_dataset['train_x'][:]\n",
    "    train_y=train_dataset['train_y'][:]\n",
    "    train_x=torch.FloatTensor(train_x)\n",
    "    train_y=torch.LongTensor(train_y)\n",
    "    return train_x,train_y\n",
    "train_x,train_y=load_dataset()\n",
    "print(train_x.size(),train_y.size(),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "train_dataset=Data.TensorDataset(train_x,train_y)\n",
    "train_loader=Data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次成本:tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第10次成本:tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第20次成本:tensor(2.4359e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第30次成本:tensor(3.1264e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第40次成本:tensor(2.5428e-06, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第50次成本:tensor(3.7787e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "第60次成本:tensor(3.7112e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-05.\n",
      "第70次成本:tensor(7.3100e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第80次成本:tensor(2.6428e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-06.\n",
      "第90次成本:tensor(1.5632e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-07.\n",
      "第100次成本:tensor(2.5866e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第110次成本:tensor(5.5106e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-08.\n",
      "第120次成本:tensor(6.2978e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第130次成本:tensor(6.7477e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第140次成本:tensor(1.4620e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第150次成本:tensor(8.0972e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第160次成本:tensor(1.9118e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第170次成本:tensor(7.7599e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第180次成本:tensor(1.3495e-08, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "第190次成本:tensor(2.5416e-07, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "    for step,(b_x,b_y) in enumerate(train_loader):\n",
    "        b_x=b_x.cuda()\n",
    "        b_y=b_y.cuda()\n",
    "        output=net(b_x)\n",
    "        loss=loss_func(output,b_y).cuda()\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    scheduler.step(loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print('第'+str(epoch)+'次成本:'+str(loss))                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(),'params_res_train_2_16.pkl')\n",
    "print('保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功\n"
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(),'params_res_train_2_16_two.pkl')\n",
    "print('保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
